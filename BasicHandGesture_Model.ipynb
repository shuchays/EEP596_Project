{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfoPdOLENABV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, AveragePooling2D, BatchNormalization, Permute, ReLU, Softmax\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "EPOCHS = args.epochs or 10\n",
        "LEARNING_RATE = args.learning_rate or 0.0005\n",
        "# If True, non-deterministic functions (e.g. shuffling batches) are not used.\n",
        "# This is False by default.\n",
        "ENSURE_DETERMINISM = args.ensure_determinism\n",
        "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "BATCH_SIZE = args.batch_size or 32\n",
        "if not ENSURE_DETERMINISM:\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=BATCH_SIZE*4)\n",
        "train_dataset=train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "\n",
        "# model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=3, kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "model.add(Conv2D(4, kernel_size=3, kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu',\n",
        "    activity_regularizer=tf.keras.regularizers.l1(0.00001)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(classes, name='y_pred', activation='softmax'))\n",
        "\n",
        "# this controls the learning rate\n",
        "opt = Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999)\n",
        "callbacks.append(BatchLoggerCallback(BATCH_SIZE, train_sample_count, epochs=EPOCHS, ensure_determinism=ENSURE_DETERMINISM))\n",
        "\n",
        "# train the neural network\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n",
        "\n",
        "# Use this flag to disable per-channel quantization for a model.\n",
        "# This can reduce RAM usage for convolutional models, but may have\n",
        "# an impact on accuracy.\n",
        "disable_per_channel_quantization = False"
      ]
    }
  ]
}